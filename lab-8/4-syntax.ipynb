{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sporting-roman",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "applicable-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cytoolz import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stock-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "driven-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('s3://ling583/sentiment.parquet', storage_options={'anon': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "meaningful-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = DocBin().from_disk('parsed.docbin')\n",
    "df['doc'] = list(docs.get_docs(nlp.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sunrise-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "severe-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(df,\n",
    "                             test_size=0.2,\n",
    "                             stratify=df['sentiment'],\n",
    "                             random_state=619)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-specific",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "automated-uncertainty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"712e6ee4cbb341cea01ead7ec17b7bba-0\" class=\"displacy\" width=\"1275\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">They</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">did</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">n't</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">have</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">any</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">clean</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">towels.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-712e6ee4cbb341cea01ead7ec17b7bba-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 575.0,2.0 575.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-712e6ee4cbb341cea01ead7ec17b7bba-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-712e6ee4cbb341cea01ead7ec17b7bba-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-712e6ee4cbb341cea01ead7ec17b7bba-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-712e6ee4cbb341cea01ead7ec17b7bba-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-712e6ee4cbb341cea01ead7ec17b7bba-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-712e6ee4cbb341cea01ead7ec17b7bba-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-712e6ee4cbb341cea01ead7ec17b7bba-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-712e6ee4cbb341cea01ead7ec17b7bba-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-712e6ee4cbb341cea01ead7ec17b7bba-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-712e6ee4cbb341cea01ead7ec17b7bba-0-5\" stroke-width=\"2px\" d=\"M595,264.5 C595,2.0 1100.0,2.0 1100.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-712e6ee4cbb341cea01ead7ec17b7bba-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,266.5 L1108.0,254.5 1092.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(\"They didn't have any clean towels.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "positive-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Token\n",
    "Token.set_extension('neg', default=False)\n",
    "# add new attribute to the negations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "certain-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in df['doc']:\n",
    "    for t in doc:\n",
    "        if t.dep_ == 'neg':\n",
    "            t.head._.neg = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "generous-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_neg(token):\n",
    "    return 'NOT:'+token.norm_ if token._.neg else token.norm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "romance-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    return [add_neg(t) for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "foreign-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "german-spouse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8986"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = make_pipeline(CountVectorizer(preprocessor=identity, tokenizer=tokenize),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-5))\n",
    "m1.fit(train['doc'], train['sentiment'])\n",
    "m1.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "controlling-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_feats(M, k=0):\n",
    "    V = M.named_steps['countvectorizer'].get_feature_names()\n",
    "    coef = M.named_steps['sgdclassifier'].coef_[0]\n",
    "    order = coef.argsort()\n",
    "    for w1, w2 in zip(order[-k:][::-1],order[:k]):\n",
    "        print(f'{V[w1]:20s} {coef[w1]:7.3f} | {V[w2]:20s} {coef[w2]:7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "prompt-edmonton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great                  5.614 | NOT:stay              -5.157\n",
      "perfect                4.925 | average               -5.054\n",
      "loved                  4.842 | ok                    -4.973\n",
      "excellent              4.418 | dirty                 -4.793\n",
      "amazing                4.232 | poor                  -4.536\n",
      "wonderful              4.001 | ruined                -4.519\n",
      "definitely             3.978 | unhelpful             -4.460\n",
      "appointed              3.820 | not                   -4.435\n",
      "comfortable            3.813 | tiny                  -4.222\n",
      "spacious               3.745 | dated                 -4.095\n",
      "pleasantly             3.719 | worst                 -4.024\n",
      "minor                  3.629 | filthy                -3.988\n",
      "NOT:beat               3.623 | dingy                 -3.974\n",
      "downside               3.603 | outdated              -3.841\n",
      "spotless               3.498 | update                -3.805\n",
      "complaint              3.478 | terrible              -3.782\n",
      "elegant                3.462 | poorly                -3.741\n",
      "screen                 3.414 | rude                  -3.570\n",
      "lovely                 3.379 | stolen                -3.565\n",
      "NOT:eat                3.364 | NOT:cleaned           -3.547\n",
      "quiet                  3.362 | updating              -3.519\n",
      "NOT:disappointed       3.319 | uncomfortable         -3.478\n",
      "recommend              3.276 | elsewhere             -3.474\n",
      "immaculate             3.100 | smelled               -3.439\n",
      "complaints             3.021 | okay                  -3.407\n"
     ]
    }
   ],
   "source": [
    "print_top_feats(m1, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "pacific-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negify(tok):\n",
    "    tok._.neg = True\n",
    "    for child in tok.children:\n",
    "        negify(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "spatial-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in df['doc']:\n",
    "    for t in doc:\n",
    "        t._.neg = False\n",
    "    for t in doc:        \n",
    "        if t.dep_ == 'neg':\n",
    "            t.head._.neg = True\n",
    "            for r in t.head.rights:\n",
    "                if r.dep_ in ['acomp', 'advmod', 'attr', 'dobj', 'prep', 'xcomp']:\n",
    "                    negify(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "continuous-beads",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.901"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = make_pipeline(CountVectorizer(preprocessor=identity, tokenizer=tokenize),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-5))\n",
    "m2.fit(train['doc'], train['sentiment'])\n",
    "m2.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "spiritual-toddler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great                  5.559 | dirty                 -5.075\n",
      "NOT:hesitate           5.338 | average               -5.043\n",
      "loved                  5.027 | ok                    -4.680\n",
      "perfect                4.702 | poor                  -4.566\n",
      "excellent              4.313 | dated                 -4.338\n",
      "comfortable            4.088 | ruined                -4.320\n",
      "wonderful              3.947 | NOT:again             -4.188\n",
      "amazing                3.895 | disappointed          -4.160\n",
      "pleasantly             3.748 | worst                 -4.111\n",
      "downside               3.656 | unhelpful             -4.055\n",
      "definitely             3.654 | filthy                -4.033\n",
      "NOT:better             3.652 | outdated              -4.005\n",
      "NOT:beat               3.647 | terrible              -3.991\n",
      "appointed              3.640 | not                   -3.984\n",
      "minor                  3.590 | tiny                  -3.935\n",
      "spacious               3.571 | horrible              -3.625\n",
      "lovely                 3.550 | rude                  -3.614\n",
      "complaint              3.533 | disappointing         -3.595\n",
      "spotless               3.467 | update                -3.522\n",
      "elegant                3.425 | uncomfortable         -3.521\n",
      "quiet                  3.343 | dingy                 -3.482\n",
      "NOT:eat                3.343 | worn                  -3.369\n",
      "pleased                3.321 | nothing               -3.356\n",
      "fantastic              3.318 | elsewhere             -3.252\n",
      "immaculate             3.180 | updating              -3.248\n"
     ]
    }
   ],
   "source": [
    "print_top_feats(m2, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "inclusive-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_tokenizer(doc):\n",
    "    return [ add_neg(w.head) + '_' + add_neg(w) for w in doc \n",
    "            if w.dep_ in ['amod', 'advmod'] ] + \\\n",
    "            [ add_neg(w) for w in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "statutory-directive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['towels_clean', 'the', 'do', 'not', 'have', 'any', 'clean', 'towels', '.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_tokenizer(nlp(\"The didn't have any clean towels.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "unique-mounting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.909"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 = make_pipeline(CountVectorizer(preprocessor=identity, tokenizer=mod_tokenizer),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-5))\n",
    "m3.fit(train['doc'], train['sentiment'])\n",
    "m3.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "identified-friendship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT:hesitate           5.042 | dirty                 -4.713\n",
      "great                  4.607 | average               -4.223\n",
      "loved                  4.549 | ok                    -3.921\n",
      "perfect                4.293 | poor                  -3.890\n",
      "excellent              3.652 | terrible              -3.841\n",
      "quiet                  3.458 | tiny                  -3.781\n",
      "amazing                3.449 | worst                 -3.741\n",
      "lovely                 3.376 | ruined                -3.669\n",
      "wonderful              3.233 | filthy                -3.647\n",
      "NOT:disappointed       3.084 | unhelpful             -3.628\n",
      "NOT:beat               3.054 | not                   -3.588\n",
      "thing_bad              3.036 | dated                 -3.486\n",
      "immaculate             3.030 | outdated              -3.216\n",
      "NOT:better             3.030 | horrible              -3.199\n",
      "NOT:eat                3.018 | disappointed          -3.178\n",
      "spotless               2.920 | rude                  -2.989\n",
      "minor                  2.880 | thing_best            -2.962\n",
      "downside               2.842 | small_so              -2.958\n",
      "recommend              2.832 | worn                  -2.908\n",
      "awesome                2.785 | told                  -2.892\n",
      "stay_again             2.778 | nothing               -2.835\n",
      "spacious               2.778 | smell                 -2.823\n",
      "pleased                2.761 | attempt               -2.720\n",
      "comfortable            2.756 | uncomfortable         -2.707\n",
      "fantastic              2.737 | dingy                 -2.698\n"
     ]
    }
   ],
   "source": [
    "print_top_feats(m3, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "classified-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def everything(doc):\n",
    "    return [ add_neg(w.head) + '_' + add_neg(w) for w in doc ] + \\\n",
    "            [ add_neg(w) for w in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "immediate-discussion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['have_the',\n",
       " 'have_do',\n",
       " 'have_not',\n",
       " 'have_have',\n",
       " 'towels_any',\n",
       " 'towels_clean',\n",
       " 'have_towels',\n",
       " 'have_.',\n",
       " 'the',\n",
       " 'do',\n",
       " 'not',\n",
       " 'have',\n",
       " 'any',\n",
       " 'clean',\n",
       " 'towels',\n",
       " '.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "everything(nlp(\"The didn't have any clean towels.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "personal-judges",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9114"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4 = make_pipeline(CountVectorizer(preprocessor=identity, tokenizer=everything),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-5))\n",
    "m4.fit(train['doc'], train['sentiment'])\n",
    "m4.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fluid-barrier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great                  5.502 | average               -4.809\n",
      "excellent              4.077 | ok                    -4.636\n",
      "perfect                3.792 | dirty                 -4.281\n",
      "wonderful              3.514 | poor                  -4.011\n",
      "comfortable            3.283 | not                   -3.934\n",
      "amazing                3.227 | worst                 -3.629\n",
      "lovely                 3.203 | terrible              -3.626\n",
      "quiet                  3.166 | no                    -3.487\n",
      "clean_very             2.849 | tiny                  -3.238\n",
      "definitely             2.789 | rude                  -3.026\n",
      "minor                  2.775 | nothing               -2.924\n",
      "loved                  2.678 | dated                 -2.922\n",
      "awesome                2.655 | horrible              -2.868\n",
      "comfortable_very       2.585 | disappointed          -2.851\n",
      "fantastic              2.527 | unhelpful             -2.641\n",
      "spacious               2.488 | NOT:again             -2.605\n",
      "appointed              2.411 | bad                   -2.553\n",
      "beautiful              2.351 | uncomfortable         -2.524\n",
      "comfy                  2.342 | in_need               -2.524\n",
      "modern                 2.292 | worn                  -2.499\n",
      "pleasantly             2.220 | need_of               -2.476\n",
      "free                   2.185 | unfriendly            -2.425\n",
      "outstanding            2.173 | elsewhere             -2.419\n",
      "stay_again             2.165 | carpet                -2.394\n",
      "best                   2.157 | filthy                -2.368\n",
      "NOT:better             2.143 | told                  -2.332\n",
      "nice                   2.132 | old                   -2.223\n",
      "immaculate             2.117 | okay                  -2.206\n",
      "everything             2.086 | barely                -2.204\n",
      "NOT:disappointed       2.055 | hotel_average         -2.199\n",
      "elegant                2.054 | small_very            -2.180\n",
      "hotel_great            2.053 | disappointing         -2.169\n",
      "spotless               2.052 | poorly                -2.138\n",
      "got_for                2.047 | outdated              -2.137\n",
      "5                      2.030 | NOT:stay_NOT:again    -2.131\n",
      "helpful                2.028 | smell                 -2.108\n",
      "be_back                1.983 | time_next             -2.107\n",
      "value_great            1.942 | ruined                -2.106\n",
      "enjoyed                1.904 | awful                 -2.099\n",
      "was_amazing            1.900 | better                -2.048\n",
      "complaint_only         1.876 | expensive_very        -2.032\n",
      "love_.                 1.866 | small_so              -2.019\n",
      "immediately            1.857 | stay_elsewhere        -2.018\n",
      "professional           1.847 | stay_short            -2.004\n",
      "problems_no            1.774 | stay_away             -1.997\n",
      "surprised_pleasantly   1.766 | dated_.               -1.987\n",
      "wine                   1.765 | dingy                 -1.966\n",
      "stay_definitely        1.746 | shabby                -1.950\n",
      "complaints             1.743 | tired                 -1.935\n",
      "pleased                1.741 | if                    -1.924\n"
     ]
    }
   ],
   "source": [
    "print_top_feats(m4, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-synthesis",
   "metadata": {},
   "source": [
    "### Summary \n",
    "\n",
    "Using the method of sentiment analysis, there are serveral advantages such as the algorithm would account for the words in different position and different meaning based on the negative and positive altitude. The final model that we have here have an accuracy of 91%, which is really good. The first 50 positive and 50 negative words seem to be very accurate and they makes sense based on the positive or negative. Like for example, positive pair of words of the hotel reviews would be great hotel, stay again, very clean, very comfortable and pleasantly surprised. On the other hand, some negative pairs of words would be very small, average hotel, need of, very expensive, and stay away. These words make perfect sense and seem very accurate. To improve the model, we can always do hyperparametize the model to get the best `min_df` and `max_df` to filter out the words that occur too often or too little. In addition, we could also try different models like the SGD classifier or the binomial model to find better outputs.  \n",
    "\n",
    "We also tried to predict setiment using a SGD classified with TfidfTransformer. The output for this model looks very promising. The accuracy and macro average F1 scores are really high. This model is very simple, too. However, this model have an accuracy of 90%, which is 1% less athan the sentiment analysis. Thus, we would go ahead and conclude that using the setiment analysis and account for words in different positioni would be more accurate and reliable, although the differences are really small. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-pilot",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
