{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mexican-midnight",
   "metadata": {},
   "source": [
    "## Lab 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "operational-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from cytoolz import * \n",
    "from tqdm.auto import tqdm \n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "injured-civilian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:46513</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>16.62 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:46513' processes=4 threads=4, memory=16.62 GB>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"tcp://127.0.0.1:46513\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "republican-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('s3://ling583/acl.parquet', storage_options = {'anon':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "combined-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribute accross cluster \n",
    "import dask.dataframe as dd\n",
    "import dask.bag as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "scheduled-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divided into 60 article per piece\n",
    "df = dd.from_pandas(df, npartitions = 100)\n",
    "texts = df['text'].to_bag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "coastal-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dated-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', exclude = ['parser', 'ner', 'lemmatizer', 'attribute_ruler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "graphic-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract candidate terms \n",
    "\n",
    "from spacy.matcher import Matcher "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "closing-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('Term', [[{'TAG': {'IN': ['JJ', 'NN']}}, \n",
    "                     {'TAG': {'IN': ['JJ', 'NN', 'IN', 'HYPH']}, 'OP': '*'}, \n",
    "                     {'TAG': 'NN'}]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "unusual-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(text):\n",
    "    doc = nlp(text)\n",
    "    spans = matcher(doc, as_spans = True)\n",
    "    return [tuple(tok.norm_ for tok in span) for span in spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "indirect-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define graph to get list of candidate per text  \n",
    "# get the freq of the candidate\n",
    "graph = texts.map(get_candidates) \\\n",
    "             .flatten() \\\n",
    "             .frequencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "prerequisite-eligibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 1.46 s, total: 11.7 s\n",
      "Wall time: 5min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "candidates = graph.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "figured-deputy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('polynomial', 'time'), 234),\n",
       " (('recognition', 'phase'), 17),\n",
       " (('input', 'string'), 379),\n",
       " (('spurious', 'ambiguity'), 148),\n",
       " (('function', 'application'), 40),\n",
       " (('relative', 'ordering'), 29),\n",
       " (('considerable', 'interest'), 40),\n",
       " (('large', 'number'), 1357),\n",
       " (('same', 'function'), 26),\n",
       " (('function', 'argument'), 5)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "controlling-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count freq and organize by len\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "divided-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = defaultdict(Counter)\n",
    "for c, f in candidates: \n",
    "    freqs[len(c)][c] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "champion-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a candidate, loook at subterms \n",
    "# if the can is 5, then look for sub seq with 4, 3, 2 terms \n",
    "\n",
    "from nltk import ngrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bound-senior",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subterms(term):\n",
    "    k = len(term)\n",
    "    for m in range(k-1, 1, -1):\n",
    "        yield from ngrams(term, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "integral-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eight-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_value(F, theta):\n",
    "    \n",
    "    termhood = Counter()\n",
    "    longer = defaultdict(list)\n",
    "    \n",
    "    for k in sorted(F, reverse = True):\n",
    "        for term in F[k]:\n",
    "            if term in longer: \n",
    "                discount = sum(longer[term]) / len(longer[term])\n",
    "            else: \n",
    "                discount = 0\n",
    "            c = log2(k) * (F[k][term] - discount)\n",
    "            if c > theta: \n",
    "                termhood[term] = c \n",
    "                for subterm in get_subterms(term):\n",
    "                    if subterm in F[len(subterm)]:\n",
    "                        longer[subterm].append(F[k][term])\n",
    "    return termhood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dying-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change theta to get more/less technical terms\n",
    "terms = c_value(freqs, theta = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "postal-fireplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5236.00 5682 language model\n",
      " 4935.26 2330 part - of - speech\n",
      " 4875.20 5388 natural language\n",
      " 4560.00 5060 machine translation\n",
      " 3599.25 3920 neural network\n",
      " 3583.00 3583 training set\n",
      " 3346.00 3346 previous work\n",
      " 3171.75 1366 end - to - end\n",
      " 3012.00 3012 other hand\n",
      " 3003.00 3003 test set\n",
      " 2923.00 2923 future work\n",
      " 2370.00 2370 target language\n",
      " 2363.18 1634 natural language processing\n",
      " 2317.22 1462 sentence - level\n",
      " 2301.37 1452 large - scale\n",
      " 2278.00 2626 co -\n",
      " 2209.44 1394 word - level\n",
      " 2174.00 2174 parse tree\n",
      " 2144.45 1353 n - gram\n",
      " 2059.00 2059 training corpus\n"
     ]
    }
   ],
   "source": [
    "# terms from top of the list \n",
    "for t, c in terms.most_common(20):\n",
    "    print(f'{c:8.2f} {freqs[len(t)][t]:4d} {\" \".join(t)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "numerical-first",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  256.00  256 candidate answer\n",
      "  255.41  110 bag - of - word\n",
      "  255.00  255 different language\n",
      "  255.00  255 novel method\n",
      "  255.00  255 dev set\n",
      "  255.00  255 abstractive summarization\n",
      "  254.00  254 head noun\n",
      "  254.00  254 regular expression\n",
      "  254.00  254 dimensional vector\n",
      "  254.00  254 random walk\n",
      "  253.00  253 meaning representation\n",
      "  253.00  253 temporal relation\n",
      "  253.00  253 model score\n",
      "  253.00  253 classification model\n",
      "  252.01  159 free word order\n",
      "  252.00  252 upper bound\n",
      "  252.00  252 summarization task\n",
      "  251.00  576 chinese word\n",
      "  251.00  251 document classification\n",
      "  250.42  158 fan - out\n"
     ]
    }
   ],
   "source": [
    "for t, c in tail(20, terms.most_common()):\n",
    "    print(f'{c:8.2f} {freqs[len(t)][t]:4d} {\" \".join(t)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "curious-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('terms.txt', 'w') as f: \n",
    "    for term in terms: \n",
    "        print(' '.join(term), file = f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
